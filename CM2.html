<!doctype html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>CM2 ‚Äì Partie 1 : Gen√®se et architecture interne de Kubernetes</title>

    <!-- ‚úÖ Style global -->
    <style>
      body {
        font-family: "Segoe UI", Roboto, sans-serif;
        line-height: 1.6;
        color: #222;
        max-width: 1000px;
        margin: auto;
        padding: 40px;
        background: #f7f9fc;
      }
      h1 {
        color: #0d47a1;
        border-bottom: 4px solid #1565c0;
        padding-bottom: 6px;
      }
      h2 {
        color: #1565c0;
        margin-top: 30px;
      }
      h3 {
        color: #1e88e5;
        margin-top: 20px;
      }
      table {
        width: 100%;
        border-collapse: collapse;
        margin: 10px 0 20px;
        background: #fff;
        border-radius: 8px;
        overflow: hidden;
      }
      th,
      td {
        padding: 10px;
        border: 1px solid #ccc;
      }
      thead {
        background: #e3f2fd;
      }
      pre {
        background: #f4f4f4;
        padding: 10px;
        border-radius: 6px;
        overflow-x: auto;
      }
      code {
        background: #f8f8f8;
        padding: 2px 5px;
        border-radius: 3px;
        font-family: Consolas, monospace;
      }
      .note {
        background: #e3f2fd;
        border-left: 5px solid #1976d2;
        padding: 10px;
        margin: 15px 0;
      }
      .warning {
        background: #fffde7;
        border-left: 5px solid #fbc02d;
        padding: 10px;
        margin: 15px 0;
      }
      .success {
        background: #e8f5e9;
        border-left: 5px solid #43a047;
        padding: 10px;
        margin: 15px 0;
      }
      hr {
        border: none;
        border-top: 1px solid #ccc;
        margin: 30px 0;
      }
    </style>

    <!-- ‚úÖ Mermaid int√©gr√© -->
    <script type="module">
      import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs";
      mermaid.initialize({ startOnLoad: true, theme: "neutral" });
    </script>
  </head>

  <body>
    <h1>CM2 ‚Äì Partie 1 : Gen√®se et architecture interne de Kubernetes</h1>

    <h2>1Ô∏è‚É£ ‚Äì Origine et philosophie de Kubernetes</h2>
    <p>
      Kubernetes est n√© au sein de <strong>Google</strong> en 2014, inspir√© d‚Äôun
      outil interne appel√© <strong>Borg</strong>. Borg g√©rait des millions de
      conteneurs dans l‚Äôinfrastructure Google. Kubernetes reprend ces principes
      tout en les ouvrant √† l‚Äôopen-source.
    </p>

    <div class="note">
      Kubernetes n‚Äôex√©cute pas directement vos applications ‚Äî il orchestre leur
      ex√©cution sur un ensemble de machines.
    </div>

    <h3>Principes fondateurs</h3>
    <ol>
      <li>
        <strong>D√©claratif</strong> : on d√©crit l‚Äô√©tat souhait√©, Kubernetes
        s‚Äôassure qu‚Äôil soit atteint.
      </li>
      <li>
        <strong>Automatis√©</strong> : planification, r√©cup√©ration et
        red√©ploiement sans intervention humaine.
      </li>
      <li>
        <strong>Distribu√©</strong> : compos√© de plusieurs services coop√©rants
        via des APIs.
      </li>
      <li>
        <strong>Extensible</strong> : chaque composant peut √™tre remplac√© ou
        enrichi par des contr√¥leurs personnalis√©s.
      </li>
    </ol>

    <hr />

    <h2>2Ô∏è‚É£ ‚Äì Le cluster Kubernetes</h2>
    <p>Un cluster Kubernetes est constitu√© de deux grandes parties :</p>

    <h3>üß† Le Control Plane</h3>
    <table>
      <thead>
        <tr>
          <th>Composant</th>
          <th>R√¥le</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>API Server</strong></td>
          <td>
            Point d‚Äôentr√©e du cluster. Re√ßoit toutes les requ√™tes
            <code>kubectl</code> ou des contr√¥leurs.
          </td>
        </tr>
        <tr>
          <td><strong>etcd</strong></td>
          <td>
            Base de donn√©es cl√©/valeur stockant l‚Äô√©tat souhait√© du cluster.
          </td>
        </tr>
        <tr>
          <td><strong>Controller Manager</strong></td>
          <td>
            Compare l‚Äô√©tat r√©el et l‚Äô√©tat d√©sir√©, et agit pour les aligner.
          </td>
        </tr>
        <tr>
          <td><strong>Scheduler</strong></td>
          <td>
            D√©termine sur quel n≈ìud ex√©cuter chaque Pod selon les ressources.
          </td>
        </tr>
        <tr>
          <td><strong>Cloud Controller</strong></td>
          <td>Int√®gre Kubernetes avec les APIs du fournisseur cloud.</td>
        </tr>
      </tbody>
    </table>

    <h3>‚öôÔ∏è Les Worker Nodes</h3>
    <table>
      <thead style="background: #e8f5e9">
        <tr>
          <th>Composant</th>
          <th>R√¥le</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>kubelet</strong></td>
          <td>
            Agent local ex√©cutant les Pods sur la machine selon les ordres du
            Control Plane.
          </td>
        </tr>
        <tr>
          <td><strong>container runtime</strong></td>
          <td>Ex√©cute les conteneurs (Docker, containerd, CRI-O...)</td>
        </tr>
        <tr>
          <td><strong>kube-proxy</strong></td>
          <td>G√®re le routage r√©seau entre Pods et Services.</td>
        </tr>
      </tbody>
    </table>

    <hr />

    <h2>3Ô∏è‚É£ ‚Äì Communication interne et API</h2>
    <p>
      Toutes les interactions passent par l‚Äô<strong>API Server</strong>, un
      serveur HTTP/JSON :
    </p>

    <ul>
      <li><code>kubectl get pods</code> ‚Üí <em>GET /api/v1/pods</em></li>
      <li>
        <code>kubectl apply -f deploy.yml</code> ‚Üí
        <em>POST /apis/apps/v1/deployments</em>
      </li>
    </ul>

    <div class="warning">
      üí° Les autres composants (Controller, Scheduler, Kubelet) ne communiquent
      qu‚Äôavec l‚ÄôAPI Server ‚Äî jamais directement entre eux.
    </div>

    <hr />

    <h2>4Ô∏è‚É£ ‚Äì Le cycle de r√©conciliation</h2>
    <p>
      Kubernetes fonctionne selon une logique de
      <strong>r√©conciliation continue</strong> :
    </p>

    <pre class="mermaid">
    flowchart LR
      subgraph Dev["Developpeur"]
        A["Manifeste YAML : etat desire"]
      end
      A -->|"kubectl apply"| B["API Server"]
      B --> C["etcd (etat desire)"]
      B --> D["Controllers"]
      D --> E{"Etat reel conforme ?"}
      E -- "Non" --> F["Creer / Remplacer / Scaler Pods"]
      F --> G["Kubelet sur les noeuds"]
      G --> H["Containers (containerd / CRI-O)"]
      H --> I["Rapport d'etat"]
      I --> D
      E -- "Oui" --> J["Convergence atteinte"]
    </pre>

    <h3>√âtapes principales</h3>
    <ol>
      <li>L‚Äôutilisateur applique un manifest YAML (ex : Deployment).</li>
      <li>
        L‚ÄôAPI Server valide et stocke la ressource dans <code>etcd</code>.
      </li>
      <li>Le Controller Manager d√©tecte qu‚Äôaucun Pod n‚Äôexiste encore.</li>
      <li>Le Scheduler assigne les Pods √† des n≈ìuds.</li>
      <li>Les kubelets cr√©ent les conteneurs correspondants.</li>
      <li>Le cluster est stable lorsque l‚Äô√©tat r√©el correspond au YAML.</li>
    </ol>

    <div class="success">
      üîÅ Kubernetes s‚Äôauto-r√©pare d√®s qu‚Äôun √©cart est d√©tect√© (self-healing).
    </div>

    <hr />

    <h2>5Ô∏è‚É£ ‚Äì Sch√©ma d‚Äôensemble</h2>

    <!-- prettier-ignore -->
    <pre class="mermaid">
    flowchart TB
      subgraph CP["Control Plane"]
        API["API Server"]
        ET["etcd"]
        CTRL["Controller Manager"]
        SCH["Scheduler"]
        CLD["Cloud Controller"]
      end
    
      subgraph W1["Worker Node 1"]
        K1["kubelet"]
        C1["containerd"]
        P1a["Pod A"]
        P1b["Pod B"]
      end
    
      subgraph W2["Worker Node 2"]
        K2["kubelet"]
        C2["containerd"]
        P2a["Pod C"]
        P2b["Pod D"]
      end
    
      API --> ET
      API --> CTRL
      API --> SCH
      API --> K1
      API --> K2
    
      K1 --> C1 --> P1a
      C1 --> P1b
      K2 --> C2 --> P2a
      C2 --> P2b
    
      K1 -. "etat" .-> API
      K2 -. "etat" .-> API
    </pre>

    <hr />

    <h2>6Ô∏è‚É£ ‚Äì Points √† retenir</h2>
    <ul>
      <li>
        Kubernetes est un <strong>syst√®me distribu√©</strong> bas√© sur une API
        unique.
      </li>
      <li>
        Le <strong>Control Plane</strong> d√©cide, les
        <strong>n≈ìuds</strong> ex√©cutent.
      </li>
      <li>
        <strong>etcd</strong> stocke l‚Äô√©tat du cluster (source de v√©rit√©).
      </li>
      <li>
        Le <strong>Scheduler</strong> et le
        <strong>Controller Manager</strong> assurent la coh√©rence.
      </li>
      <li>
        Le <strong>Kubelet</strong> relie les manifests YAML √† la r√©alit√© des
        conteneurs.
      </li>
    </ul>

    <div class="note">
      üß© Prochaine partie : Le mod√®le d√©claratif et la structure des manifests
      YAML.
    </div>
    <hr />
    <h1>CM2 ‚Äì Partie 2 : Le mod√®le d√©claratif et les manifests YAML</h1>

    <h2>1Ô∏è‚É£ ‚Äì Le mod√®le d√©claratif de Kubernetes</h2>
    <p>
      Kubernetes repose sur une approche <strong>d√©clarative</strong> : on
      d√©crit l‚Äô√©tat final souhait√© du syst√®me, sans pr√©ciser les √©tapes
      d‚Äôex√©cution.
    </p>

    <div class="note">
      üí° On d√©clare <em>ce que l‚Äôon veut obtenir</em>, pas
      <em>comment l‚Äôobtenir</em>.
    </div>

    <h3>‚öôÔ∏è Exemple conceptuel</h3>
    <pre><code>replicas: 3</code></pre>
    <p>
      Cela indique simplement √† Kubernetes : ¬´ Assure-toi qu‚Äôil y ait toujours
      trois r√©plicas actifs. ¬ª Si un conteneur tombe, Kubernetes en relance un
      automatiquement.
    </p>

    <div class="success">
      ‚úÖ Le cluster devient auto-r√©parant et auto-adaptatif (scaling, update,
      rollback).
    </div>

    <hr />

    <h2>2Ô∏è‚É£ ‚Äì Le r√¥le du YAML</h2>
    <p>
      Le YAML est la grammaire d√©clarative utilis√©e pour d√©crire les ressources
      Kubernetes (les manifests).
    </p>

    <h3>üß© Structure de base</h3>
    <pre><code>apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  MODE: "production"
  TIMEOUT: "30"
</code></pre>

    <h3>üìã Sections fondamentales</h3>
    <table>
      <thead>
        <tr>
          <th>Cl√©</th>
          <th>R√¥le</th>
          <th>Exemple</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><code>apiVersion</code></td>
          <td>Version de l‚ÄôAPI utilis√©e</td>
          <td><code>v1</code>, <code>apps/v1</code></td>
        </tr>
        <tr>
          <td><code>kind</code></td>
          <td>Type d‚Äôobjet</td>
          <td><code>Pod</code>, <code>Service</code></td>
        </tr>
        <tr>
          <td><code>metadata</code></td>
          <td>Identifiants (nom, labels, namespace)</td>
          <td><code>name: webapp</code></td>
        </tr>
        <tr>
          <td><code>spec</code></td>
          <td>Sp√©cifications fonctionnelles</td>
          <td><code>replicas</code>, <code>containers</code></td>
        </tr>
      </tbody>
    </table>

    <hr />

    <h2>3Ô∏è‚É£ ‚Äì Du manifest au cluster : la cha√Æne de traitement</h2>

    <pre class="mermaid">
flowchart LR
  A["Manifest YAML"] --> B["API Server"]
  B --> C["etcd (base cl√©-valeur)"]
  C --> D["Controller Manager"]
  D --> E["Scheduler"]
  E --> F["Kubelet (sur le n≈ìud)"]
  F --> G["Conteneur cr√©√©"]
    </pre>

    <ol>
      <li>
        <code>kubectl apply -f fichier.yaml</code> ‚Üí envoi du manifest √† l‚ÄôAPI
        Server.
      </li>
      <li>Validation et stockage dans <strong>etcd</strong>.</li>
      <li>
        <strong>Controller Manager</strong> cr√©e ou met √† jour les objets.
      </li>
      <li><strong>Scheduler</strong> assigne les Pods aux n≈ìuds.</li>
      <li>
        <strong>Kubelet</strong> cr√©e les conteneurs et signale leur √©tat.
      </li>
    </ol>

    <div class="warning">
      ‚öôÔ∏è Kubernetes agit tant que l‚Äô√©tat r√©el diff√®re du manifest : c‚Äôest la
      <em>r√©conciliation continue</em>.
    </div>

    <hr />

    <h2>4Ô∏è‚É£ ‚Äì <code>kubectl create</code> vs <code>kubectl apply</code></h2>
    <h3>‚ú≥Ô∏è <code>kubectl create</code></h3>
    <pre><code>kubectl create deployment web --image=nginx</code></pre>
    <p>
      Cr√©e un objet et l‚Äôenregistre dans <code>etcd</code>. M√™me si la commande
      semble imp√©rative, Kubernetes la traduit en une
      <strong>d√©claration d‚Äô√©tat</strong>.
    </p>

    <h3>üß© <code>kubectl apply</code></h3>
    <pre><code>kubectl apply -f deployment.yaml</code></pre>
    <p>
      Applique ou met √† jour un manifest existant : Kubernetes modifie
      uniquement ce qui est n√©cessaire pour atteindre l‚Äô√©tat souhait√©.
    </p>

    <table>
      <thead style="background: #f1f8e9">
        <tr>
          <th>Commande</th>
          <th>Nature</th>
          <th>Usage</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><code>create</code></td>
          <td>D√©claratif instantan√©</td>
          <td>Cr√©ation rapide</td>
        </tr>
        <tr>
          <td><code>apply</code></td>
          <td>D√©claratif continu</td>
          <td>Mise √† jour automatique</td>
        </tr>
      </tbody>
    </table>

    <hr />

    <h2>5Ô∏è‚É£ ‚Äì Typologie des objets Kubernetes</h2>
    <table>
      <thead>
        <tr>
          <th>Cat√©gorie</th>
          <th>Objets</th>
          <th>R√¥le</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Workload</td>
          <td>Pod, ReplicaSet, Deployment</td>
          <td>D√©ploient et maintiennent les conteneurs</td>
        </tr>
        <tr>
          <td>Service & R√©seau</td>
          <td>Service, Ingress</td>
          <td>Assurent la connectivit√©</td>
        </tr>
        <tr>
          <td>Configuration</td>
          <td>ConfigMap, Secret</td>
          <td>Fournissent les param√®tres</td>
        </tr>
        <tr>
          <td>Infrastructure</td>
          <td>Node, Namespace, PV</td>
          <td>D√©crivent les ressources physiques/logiques</td>
        </tr>
        <tr>
          <td>S√©curit√©</td>
          <td>RBAC, NetworkPolicy</td>
          <td>G√®rent les acc√®s et l‚Äôisolation</td>
        </tr>
      </tbody>
    </table>

    <h3>Exemple : un Deployment complet</h3>
    <pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-deploy
  labels:
    app: web
spec:
  replicas: 2
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      containers:
        - name: web
          image: nginx:1.25
          ports:
            - containerPort: 80
</code></pre>

    <hr />

    <h2>6Ô∏è‚É£ ‚Äì Manifests multi-documents</h2>
    <pre><code>---
apiVersion: v1
kind: Namespace
metadata:
  name: demo
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web
  namespace: demo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      containers:
        - name: web
          image: nginx:1.25
---
apiVersion: v1
kind: Service
metadata:
  name: web-svc
  namespace: demo
spec:
  selector:
    app: web
  ports:
    - port: 80
      targetPort: 80
</code></pre>
    <p>
      D√©ploiement complet en une commande :<br />
      <code>kubectl apply -f stack-demo.yaml</code>
    </p>

    <hr />

    <h2>7Ô∏è‚É£ ‚Äì V√©rification et inspection</h2>
    <table>
      <thead>
        <tr>
          <th>Action</th>
          <th>Commande</th>
          <th>R√©sultat</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Lister les ressources</td>
          <td><code>kubectl get all -n demo</code></td>
          <td>Tous les objets du namespace</td>
        </tr>
        <tr>
          <td>D√©tails</td>
          <td><code>kubectl describe deployment web -n demo</code></td>
          <td>Informations et √©v√©nements</td>
        </tr>
        <tr>
          <td>YAML actuel</td>
          <td><code>kubectl get deploy web -o yaml</code></td>
          <td>√âtat d√©clar√© du manifest</td>
        </tr>
        <tr>
          <td>Pods</td>
          <td><code>kubectl get pods -o wide</code></td>
          <td>IPs, n≈ìuds, statuts</td>
        </tr>
      </tbody>
    </table>

    <hr />

    <h2>8Ô∏è‚É£ ‚Äì Points p√©dagogiques cl√©s</h2>
    <ul>
      <li>Kubernetes est <strong>pilot√© par des manifests</strong> YAML.</li>
      <li>L‚Äôutilisateur ne manipule pas les conteneurs mais les objets API.</li>
      <li>
        Le <strong>Control Plane</strong> maintient la coh√©rence entre √©tat
        d√©sir√© et r√©el.
      </li>
      <li>
        Le YAML est la <strong>grammaire du dialogue</strong> humain/cluster.
      </li>
      <li>M√™me <code>kubectl create</code> reste d√©claratif.</li>
    </ul>

    <div class="note">
      üß© Prochaine partie : Isolation logique, exposition r√©seau et structure
      applicative (Namespaces, Services, Ingress).
    </div>
    <hr />
    <h1>
      CM2 ‚Äì Partie 3 : Isolation, organisation et exposition dans Kubernetes
    </h1>

    <h2>1Ô∏è‚É£ ‚Äì Introduction : du manifest √† la structure du cluster</h2>
    <p>
      Apr√®s avoir d√©couvert comment d√©crire les objets Kubernetes
      (<code>Pods</code>, <code>Deployments</code>, <code>Services</code>) via
      YAML, nous abordons maintenant la
      <strong>structure logique et r√©seau</strong> du cluster.
    </p>

    <p>
      Kubernetes est un syst√®me <strong>d√©claratif et auto-r√©gul√©</strong> : le
      Control Plane s'assure que l'√©tat du cluster correspond en permanence √†
      l'√©tat d√©clar√©. Cette r√©conciliation s'applique non seulement aux objets
      applicatifs, mais aussi √† la fa√ßon dont les applications sont organis√©es,
      expos√©es et isol√©es.
    </p>

    <ul>
      <li><strong>organise</strong> les ressources avec les namespaces ;</li>
      <li>
        <strong>connecte</strong> les composants via les services internes ;
      </li>
      <li>
        <strong>expose</strong> les applications vers l‚Äôext√©rieur avec les
        ingress ;
      </li>
      <li><strong>prot√®ge</strong> le trafic avec les politiques r√©seau.</li>
    </ul>

    <hr />

    <h2>2Ô∏è‚É£ ‚Äì Les Namespaces : l'isolation logique du cluster</h2>

    <h3>2.1. R√¥le fondamental</h3>
    <p>
      Un <strong>namespace</strong> est un espace logique d'isolation √†
      l'int√©rieur d'un cluster. Il sert √†
      <strong>segmenter et organiser</strong> les ressources selon des domaines
      fonctionnels, des √©quipes, ou des applications.
    </p>

    <div class="note">
      ‚ú® Un cluster Kubernetes = une ville partag√©e.<br />
      Les namespaces = les quartiers isol√©s avec leurs propres r√®gles, habitants
      et ressources.
    </div>

    <h3>2.2. Bonnes pratiques d'organisation</h3>
    <ul>
      <li>
        <strong>Isoler les applications</strong> : <code>frontend</code>,
        <code>backend</code>, <code>database</code>, <code>monitoring</code>.
      </li>
      <li>
        <strong>Isoler les √©quipes ou clients</strong> : <code>team-a</code>,
        <code>client-x</code>, <code>client-y</code>.
      </li>
      <li>
        <strong>G√©rer la s√©curit√©</strong> : quotas, limites CPU/m√©moire,
        secrets, r√¥les RBAC.
      </li>
    </ul>

    <p>
      Les environnements <strong>dev/staging/prod</strong> devraient reposer sur
      des <strong>clusters distincts</strong> pour √©viter les fuites de s√©curit√©
      et garantir la r√©silience.
    </p>

    <h3>2.3. Commandes pratiques</h3>
    <pre><code>kubectl get ns
kubectl create ns analytics
kubectl config set-context --current --namespace=analytics
kubectl get all -n analytics
</code></pre>

    <h3>2.4. Namespace par d√©faut et objets globaux</h3>
    <p>
      Si aucun namespace n'est sp√©cifi√©, Kubernetes cr√©e l'objet dans le
      namespace <strong>default</strong>.<br />
      Certains objets sont globaux : <code>Node</code>, <code>Namespace</code>,
      <code>ClusterRole</code>, <code>PersistentVolume</code>.
    </p>

    <h3>2.5. Discussion critique : Namespaces, Zero Trust et architecture</h3>
    <ul>
      <li>
        Kubernetes est <strong>une plateforme de production</strong>, pas un
        outil de sandbox.
      </li>
      <li>
        Les environnements s√©par√©s reposent sur des
        <strong>clusters distincts</strong>, pas sur des namespaces.
      </li>
    </ul>

    <h4>üîí R√¥le s√©curitaire</h4>
    <ul>
      <li>
        Limite la surface d‚Äôattaque en cloisonnant les ressources et les acc√®s.
      </li>
      <li>
        Les communications inter-namespaces peuvent √™tre restreintes par des
        <code>NetworkPolicies</code>.
      </li>
      <li>
        En approche <strong>Zero Trust</strong>, rien n‚Äôest implicitement
        autoris√©.
      </li>
    </ul>

    <h4>üïµÔ∏è‚Äç‚ôÇÔ∏è Sch√©mas d‚Äôisolation possibles</h4>
    <ol>
      <li><strong>Namespace unique</strong> : simple mais expos√©.</li>
      <li>
        <strong>Multi-namespaces applicatifs</strong> : front/back/data s√©par√©s.
      </li>
      <li><strong>Multi-clusters</strong> : isolation totale (prod).</li>
    </ol>

    <hr />

    <h2>3Ô∏è‚É£ ‚Äì Les Services : connecter et stabiliser le r√©seau interne</h2>

    <p>
      Les Pods sont √©ph√©m√®res : leurs IP changent √† chaque recr√©ation. Les
      <strong>Services</strong> fournissent une adresse stable et un
      <strong>m√©canisme de d√©couverte interne (DNS)</strong>.
    </p>

    <h3>3.2. Types de Services</h3>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Port√©e</th>
          <th>R√¥le</th>
          <th>Cas d‚Äôusage</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><code>ClusterIP</code></td>
          <td>Interne</td>
          <td>Point d‚Äôacc√®s interne</td>
          <td>Communication entre microservices</td>
        </tr>
        <tr>
          <td><code>NodePort</code></td>
          <td>Interne + externe</td>
          <td>Port fixe sur chaque n≈ìud</td>
          <td>D√©monstrations locales</td>
        </tr>
        <tr>
          <td><code>LoadBalancer</code></td>
          <td>Externe</td>
          <td>Exposition publique</td>
          <td>Production</td>
        </tr>
        <tr>
          <td><code>ExternalName</code></td>
          <td>DNS externe</td>
          <td>Redirection</td>
          <td>API ou base distante</td>
        </tr>
      </tbody>
    </table>

    <h3>3.3. Exemple YAML</h3>
    <pre><code>apiVersion: v1
kind: Service
metadata:
  name: api-svc
  namespace: backend
spec:
  selector:
    app: api
  ports:
    - port: 8080
      targetPort: 8080
  type: ClusterIP
</code></pre>

    <p>
      Chaque Service obtient un nom DNS automatique :
      <code>api-svc.backend.svc.cluster.local</code>
    </p>

    <div class="note">
      Le DNS interne est g√©r√© par <strong>CoreDNS</strong> (Pod dans
      <code>kube-system</code>).
    </div>

    <hr />

    <h2>4Ô∏è‚É£ ‚Äì L‚ÄôIngress : exposer les applications vers l‚Äôext√©rieur</h2>
    <p>
      Les Services <code>NodePort</code> ou <code>LoadBalancer</code> sont
      utiles mais limit√©s. L‚Äôobjet <strong>Ingress</strong> d√©crit des r√®gles de
      routage HTTP(S) g√©r√©es par un
      <strong>Ingress Controller</strong> (Traefik, Nginx, Istio...).
    </p>

    <h3>4.2. Exemple YAML</h3>
    <pre><code>apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: web-ingress
  namespace: frontend
  annotations:
    kubernetes.io/ingress.class: traefik
spec:
  rules:
    - host: web.example.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: web-svc
                port:
                  number: 80
</code></pre>

    <h3>4.3. Sch√©ma logique</h3>
    <pre class="mermaid">
graph LR
  User["Navigateur web"] --> Ingress["Ingress Controller (Traefik/Nginx)"]
  Ingress --> Service["Service ClusterIP"]
  Service --> Pod1["Pod web-1"]
  Service --> Pod2["Pod web-2"]
    </pre>

    <div class="warning">
      L‚ÄôIngress agit comme un <strong>proxy inverse HTTP/TLS</strong>,
      appliquant les r√®gles de routage et les certificats.
    </div>

    <hr />

    <h2>5Ô∏è‚É£ ‚Äì L‚ÄôEgress et les NetworkPolicies : contr√¥ler le trafic sortant</h2>
    <p>
      Par d√©faut, les Pods peuvent communiquer librement. Il faut donc
      <strong>restreindre le trafic</strong> et appliquer le principe du
      <em>moindre privil√®ge</em>.
    </p>

    <h3>5.2. Exemple de NetworkPolicy</h3>
    <pre><code>apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: restrict-egress
  namespace: backend
spec:
  podSelector:
    matchLabels:
      app: api
  policyTypes:
    - Egress
  egress:
    - to:
        - ipBlock:
            cidr: 10.0.0.0/8
</code></pre>

    <p>
      Cette politique interdit tout trafic sortant sauf vers le r√©seau interne
      <code>10.0.0.0/8</code>.
    </p>

    <ul>
      <li><code>Ingress</code> = flux entrant vers les Pods.</li>
      <li><code>Egress</code> = flux sortant des Pods.</li>
      <li><code>NetworkPolicy</code> = pare-feu logique au niveau du Pod.</li>
      <li>
        <strong>Zero Trust</strong> : tout est ferm√© par d√©faut, ouvert par
        exception.
      </li>
    </ul>

    <hr />

    <h2>6Ô∏è‚É£ ‚Äì Sch√©ma r√©capitulatif</h2>
    <pre class="mermaid">
graph TD
  subgraph Cluster["Cluster Kubernetes"]
    subgraph NamespaceA["Namespace: frontend"]
      I["Ingress Controller"]
      S1["Service web-svc"]
      P1["Pod web-1"]
      P2["Pod web-2"]
    end
    subgraph NamespaceB["Namespace: backend"]
      S2["Service api-svc"]
      P3["Pod api-1"]
      P4["Pod api-2"]
    end
  end
  User["Navigateur"] --> I --> S1 --> P1 & P2
  P1 --> S2 --> P3
  P3 -.->|"Egress contr√¥l√©"| ExternalDB["Base de donn√©es externe (SaaS)"]
    </pre>

    <hr />

    <h2>7Ô∏è‚É£ ‚Äì Conclusion de la Partie 3</h2>
    <ul>
      <li>
        Les <strong>namespaces</strong> isolent la logique et la s√©curit√© du
        cluster.
      </li>
      <li>
        Les <strong>services</strong> stabilisent les connexions internes.
      </li>
      <li>
        Les <strong>ingress</strong> exposent les apps via un contr√¥leur
        HTTP/TLS.
      </li>
      <li>
        Les <strong>network policies</strong> contr√¥lent finement les flux.
      </li>
    </ul>

    <div class="success">
      Ensemble, ces m√©canismes composent une infrastructure segment√©e,
      d√©clarative et s√©curis√©e.
    </div>

    <div class="note">
      üß© Le TD4 prolongera cette approche avec la mise en place concr√®te de
      <strong>Traefik (Ingress Controller)</strong>, l‚Äôexploration du r√©seau
      inter-pods, et l‚Äôobservation via <strong>Lens</strong> et
      <strong>Prometheus</strong>.
    </div>
  </body>
</html>
