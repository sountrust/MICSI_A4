
<!doctype html>
<html lang="fr">
<head>
  <meta charset="utf-8">
  <title>Présentation Microservices</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js/dist/reveal.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js/dist/theme/white.css">
</head>
<body>
  <div class="reveal">
    <div class="slides">
      <h1>Du monolithe aux microservices</h1>
<p>Une application monolithique regroupe toutes les fonctionnalités dans un seul programme.</p>
<ul>
<li>Une base de code unique, un seul processus, un seul cycle de déploiement.</li>
<li>Simplicité initiale mais forte dépendance interne entre les modules.</li>
<li>Tout changement ou panne impacte l’ensemble du système.</li>
</ul>
<p>Lien recommandé : <a href="https://cloud.google.com/kubernetes-engine/kubernetes-comic/">BD Kubernetes par Google Cloud</a></p>
<hr />
<h1>Historique et contexte d'évolution</h1>
<p>Dans les années 1990–2000, la majorité des applications d’entreprise étaient <strong>monolithiques</strong>.</p>
<ul>
<li>Modèle client-serveur : un serveur central, un code unique.</li>
<li>Les mises à jour exigeaient souvent l’arrêt complet du service.</li>
<li>La montée en charge reposait sur du matériel plus puissant (scalabilité verticale).</li>
</ul>
<p>Progressivement, plusieurs facteurs ont poussé à découper le monolithe :</p>
<ul>
<li><strong>Complexification</strong> des systèmes (nombre croissant de fonctionnalités).</li>
<li><strong>Émergence du web</strong> et besoin d’intégration entre services externes.</li>
<li><strong>Nouveaux paradigmes</strong> de développement collaboratif (DevOps, intégration continue).</li>
</ul>
<p>Les premiers découpages se sont appuyés sur des <strong>protocoles légers</strong> et des <strong>API standardisées</strong> :</p>
<ul>
<li><strong>SOAP (1999)</strong> et les <em>Web Services</em> XML → premières tentatives d’interopérabilité.</li>
<li><strong>REST (2000)</strong> → communication simple sur HTTP avec formats légers (JSON, XML).</li>
<li><strong>gRPC (2015)</strong> → protocole binaire efficace basé sur HTTP/2 et Protobuf.</li>
</ul>
<p>Ces technologies ont permis à des modules indépendants de dialoguer entre eux, amorçant la transition vers les microservices.</p>
<hr />
<h1>Qu’est-ce qu’un microservice ?</h1>
<p>Un <strong>microservice</strong> est une unité logique et fonctionnelle d’une application.</p>
<ul>
<li>Il implémente une fonction métier unique (ex. : facturation, authentification, API produit).</li>
<li>Il s’exécute de manière <strong>indépendante</strong>, souvent sur une instance séparée.</li>
<li>Chaque microservice a son propre cycle de développement et de déploiement.</li>
</ul>
<p>Les microservices communiquent entre eux par des <strong>APIs légères</strong>, favorisant :</p>
<ul>
<li>la <strong>modularité</strong> du code,</li>
<li>la <strong>tolérance aux pannes</strong>,</li>
<li>la <strong>scalabilité horizontale</strong> (chaque service peut être répliqué selon la charge).</li>
</ul>
<p>Cependant, cette modularité introduit de nouveaux défis : gestion de l’infrastructure, du réseau et du déploiement.</p>
<hr />
<h1>Microservice vs conteneur</h1>
<p>❌ Un <strong>microservice n’est pas un conteneur</strong>.</p>
<ul>
<li>Le microservice est un <strong>concept logiciel</strong> (composant applicatif indépendant).</li>
<li>Le conteneur est un <strong>mécanisme d’exécution</strong> (environnement isolé pour un processus).</li>
</ul>
<p>✔️ Un <strong>conteneur</strong> héberge souvent un <strong>microservice</strong> :</p>
<ul>
<li>Il contient le code, les dépendances et le runtime nécessaires à l’exécution.</li>
<li>Il garantit la cohérence entre environnements de développement et de production.</li>
<li>Il assure <strong>l’immutabilité</strong> : un conteneur déployé ne change pas, il est remplacé lors d’une mise à jour.</li>
<li>Il offre <strong>l’interopérabilité</strong> : le même conteneur fonctionne sur tout hôte supportant un moteur de conteneurisation.</li>
</ul>
<hr />
<h1>Pourquoi la conteneurisation est essentielle</h1>
<p>La conteneurisation répond aux limites des microservices déployés manuellement.</p>
<ul>
<li>Elle fournit un <strong>environnement portable, standardisé et isolé</strong>.</li>
<li>Elle favorise l’<strong>immutabilité</strong> : on remplace les instances au lieu de les modifier.</li>
<li>Elle favorise l’<strong>interopérabilité</strong> : les images fonctionnent sur n’importe quel système compatible.</li>
<li>Elle simplifie le <strong>déploiement et la montée en charge automatique</strong>.</li>
<li>Elle permet la <strong>résilience</strong> : les conteneurs peuvent être recréés automatiquement.</li>
</ul>
<p>Ces deux propriétés — <strong>immutabilité</strong> et <strong>interopérabilité</strong> — sont au cœur de la philosophie cloud-native que Kubernetes orchestre à grande échelle.</p>
<hr />
<h1>Limites du modèle monolithique</h1>
<ul>
<li>Difficulté à faire évoluer ou à corriger sans recompiler tout le projet.</li>
<li>Scalabilité uniquement <strong>verticale</strong> (plus de CPU/RAM sur une seule machine).</li>
<li>Déploiement lent et risqué : un bug peut interrompre tout le service.</li>
<li>Couplage fort entre équipes et technologies : impossible de faire cohabiter plusieurs stacks.</li>
</ul>
<p>Exemple de processus monolithique :</p>
<pre><code class="language-bash">java -jar application-complete.jar
</code></pre>
<p>Un seul binaire qui contient API, interface web, logique métier et accès aux données.</p>
<hr />
<h1>Vers la modularité : l’idée des microservices</h1>
<p>Le découpage en <strong>microservices</strong> vise à isoler chaque fonction dans un service autonome.</p>
<ul>
<li>Chaque microservice possède son propre code, ses dépendances, et sa base de données.</li>
<li>Communication par API (HTTP, gRPC, message bus…).</li>
<li>Permet une <strong>scalabilité horizontale</strong> : on réplique uniquement les parties sollicitées.</li>
<li>Facilite les pipelines CI/CD : chaque service peut être testé et déployé indépendamment.</li>
</ul>
<hr />
<h1>Du point de vue architectural</h1>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>Monolithe</th>
<th>Microservices</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Couplage</strong></td>
<td>Fort</td>
<td>Faible</td>
</tr>
<tr>
<td><strong>Déploiement</strong></td>
<td>Unique</td>
<td>Indépendant</td>
</tr>
<tr>
<td><strong>Scalabilité</strong></td>
<td>Verticale</td>
<td>Horizontale</td>
</tr>
<tr>
<td><strong>Résilience</strong></td>
<td>Panne globale</td>
<td>Isolement des pannes</td>
</tr>
<tr>
<td><strong>Complexité réseau</strong></td>
<td>Faible</td>
<td>Élevée (API, discovery, sécurité)</td>
</tr>
</tbody>
</table>
<p>Les microservices déplacent la complexité du code vers l’infrastructure réseau.</p>
<hr />
<h1>Problème nouveau : comment exécuter tous ces services ?</h1>
<p>Avec plusieurs microservices, chaque composant doit :</p>
<ul>
<li>Être isolé de manière fiable.</li>
<li>Communiquer avec les autres services.</li>
<li>Être mis à jour et supervisé sans perturber le reste.</li>
</ul>
<p>Cela demande un <strong>mécanisme d’isolation et de gestion</strong> :
➡️ <strong>la virtualisation</strong> pour séparer les environnements,
➡️ <strong>la conteneurisation</strong> pour isoler les processus applicatifs.</p>
<p>Les deux technologies sont complémentaires :</p>
<ul>
<li>La virtualisation fournit la base matérielle.</li>
<li>La conteneurisation offre la flexibilité logicielle.</li>
</ul>
<hr />
<h1>Exemple de transition pratique</h1>
<p>Une équipe passe d’un monolithe à un premier microservice :</p>
<pre><code class="language-bash"># Monolithe initial
java -jar monolith.jar

# Microservice isolé
python3 -m http.server 8080
</code></pre>
<p>Le service est désormais indépendant…
Mais pour en gérer <strong>dizaines ou centaines</strong>, il faudra les <strong>isoler</strong>, les <strong>connecter</strong> et les <strong>orchestrer</strong>.</p>
<p>➡️ Ce besoin mènera naturellement vers la virtualisation et la conteneurisation.</p>
<h1>Virtualisation : l'isolation matérielle</h1>
<p>La virtualisation est la première étape vers la mutualisation efficace des ressources informatiques. Elle permet de faire fonctionner plusieurs systèmes d’exploitation et environnements logiciels sur un même matériel physique ou sur un ensemble de matériels agrégés.</p>
<hr />
<h1>Définition et principe</h1>
<p>La <strong>virtualisation</strong> consiste à créer plusieurs environnements indépendants appelés <strong>machines virtuelles (VM)</strong> à partir d’un ensemble de ressources physiques.</p>
<ul>
<li>Chaque VM dispose de son propre système d’exploitation, de son espace mémoire, de son stockage et de ses interfaces réseau.</li>
<li>Ces environnements sont totalement isolés les uns des autres.</li>
<li>Un <strong>hyperviseur</strong> orchestre la répartition et l’utilisation des ressources physiques.</li>
</ul>
<p>Mais un hyperviseur ne se contente pas de diviser les ressources :</p>
<ul>
<li>Il peut <strong>agréger plusieurs ressources matérielles de même type</strong> (par exemple plusieurs processeurs physiques ou disques) pour les présenter comme une seule ressource virtuelle.</li>
<li>Il peut ensuite <strong>rediviser</strong> cette ressource agrégée en plusieurs ressources virtuelles indépendantes des ressources matérielles sous-jacentes.</li>
</ul>
<p>Ainsi, la virtualisation permet de découpler totalement l’environnement d’exécution des contraintes matérielles réelles.</p>
<hr />
<h1>Les deux grands types d’hyperviseurs</h1>
<h3>Hyperviseur de type 1 – <em>bare-metal</em></h3>
<ul>
<li>Fonctionne directement sur le matériel physique.</li>
<li>Il gère le CPU, la mémoire, le stockage et le réseau sans passer par un OS hôte.</li>
<li>Performances élevées, fiabilité accrue.</li>
<li>Utilisé dans les environnements serveurs et data centers.</li>
</ul>
<p><strong>Exemples :</strong> VMware ESXi, Microsoft Hyper-V, KVM, Xen.</p>
<h3>Hyperviseur de type 2 – <em>hébergé</em></h3>
<ul>
<li>Fonctionne au-dessus d’un système d’exploitation déjà existant.</li>
<li>Il virtualise les ressources fournies par l’OS hôte.</li>
<li>Plus simple à installer, adapté aux postes de travail ou environnements de test.</li>
</ul>
<p><strong>Exemples :</strong> VirtualBox, VMware Workstation, Parallels Desktop.</p>
<hr />
<h1>Rôle de l'hyperviseur</h1>
<p>L’hyperviseur agit comme une couche d’abstraction entre le matériel et les machines virtuelles.</p>
<ul>
<li>Il <strong>alloue dynamiquement</strong> les ressources physiques selon les besoins des VMs.</li>
<li>Il <strong>isole</strong> les environnements virtuels pour éviter toute interférence.</li>
<li>Il <strong>agrège</strong> ou <strong>fractionne</strong> les ressources matérielles de manière transparente.</li>
</ul>
<p>Schéma conceptuel :</p>
<pre><code>Matériel physique (CPU, RAM, disque, réseau)
   ↓
Hyperviseur
   ↓ ↓ ↓
VM1 (Linux) | VM2 (Windows) | VM3 (Ubuntu Server)
</code></pre>
<hr />
<h1>Avantages de la virtualisation</h1>
<ul>
<li><strong>Isolation complète</strong> : chaque VM est un environnement indépendant.</li>
<li><strong>Mutualisation</strong> : meilleure utilisation des ressources matérielles.</li>
<li><strong>Portabilité</strong> : les VMs peuvent être déplacées ou copiées sur d’autres hôtes.</li>
<li><strong>Flexibilité</strong> : création rapide d’environnements de test ou de production.</li>
<li><strong>Abstraction</strong> : indépendance entre le matériel réel et les environnements exécutés.</li>
</ul>
<p>Exemple pratique : un serveur physique peut héberger plusieurs services (base de données, serveur web, stockage) chacun dans sa propre VM.</p>
<hr />
<h1>Limites de la virtualisation</h1>
<ul>
<li><strong>Surcharge système</strong> : chaque VM embarque un OS complet → consommation mémoire importante.</li>
<li><strong>Temps de démarrage élevé</strong> comparé aux conteneurs.</li>
<li><strong>Complexité de gestion</strong> : maintenance et mises à jour multiples.</li>
</ul>
<p>Pour répondre à cette complexité, de nouvelles approches sont apparues :</p>
<h3>Infrastructure as Code (IaC)</h3>
<p>L’<strong>Infrastructure as Code</strong> propose une approche <strong>déclarative</strong> de la gestion des environnements.</p>
<ul>
<li>L’administrateur ou le développeur <strong>décrit l’état attendu</strong> de l’infrastructure (réseaux, machines, services, règles).</li>
<li>Un outil d’automatisation se charge de <strong>créer, configurer ou mettre à jour</strong> les ressources pour atteindre cet état.</li>
<li>Cette approche rapproche la gestion d’infrastructure de la logique logicielle : versionnage, réutilisation, et reproductibilité.</li>
</ul>
<p><strong>Exemples d’outils IaC :</strong></p>
<ul>
<li>Terraform / OpenTofu : gestion d’infrastructures multi-clouds.</li>
<li>Ansible, Puppet, Chef : automatisation des configurations.</li>
<li>CloudFormation, Pulumi : gestion déclarative native du cloud.</li>
</ul>
<p>Cette logique <strong>déclarative</strong>, déjà au cœur de la virtualisation moderne, sera reprise et amplifiée dans la conteneurisation et l’orchestration (voir section 4 sur Kubernetes).</p>
<hr />
<h1>De la virtualisation à la conteneurisation</h1>
<p>La conteneurisation ne remplace pas la virtualisation, elle s’appuie sur elle.</p>
<ul>
<li>Les VMs assurent l’isolation matérielle.</li>
<li>Les conteneurs assurent l’isolation logicielle (niveau processus).</li>
</ul>
<p>En pratique :</p>
<ul>
<li>Un cluster Kubernetes est souvent déployé <strong>sur des VMs</strong> (dans le cloud ou sur un hyperviseur local).</li>
<li>Les conteneurs s’exécutent <strong>à l’intérieur</strong> de ces VMs.</li>
</ul>
<p>Ce modèle combine la <strong>sécurité et la robustesse de la virtualisation</strong> avec la <strong>légèreté et la rapidité des conteneurs</strong>, fondant les architectures modernes dites <em>cloud-native</em>.</p>
    </div>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/reveal.js/dist/reveal.js"></script>
  <script>
    Reveal.initialize();
  </script>
</body>
</html>
